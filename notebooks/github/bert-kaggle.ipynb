{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls ..","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pwd","execution_count":null,"outputs":[]},{"metadata":{"id":"VtfD5gY8_zQM","trusted":true},"cell_type":"code","source":"import pandas as pd\nfrom transformers import BertForSequenceClassification, Trainer, TrainingArguments\nimport torch","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import zipfile\n\npath_to_zip_file = \"../input/train.zip\"\ndirectory_to_extract_to = \"./\"\n\n\n#simple function to extract the train data\ndef extract(zip_file, path):\n    with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n        zip_ref.extractall(path)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#extract('/kaggle/input/text-classification/github.tar', '/kaggle/working/datasets')","execution_count":null,"outputs":[]},{"metadata":{"id":"L0kV2j_D_zQM"},"cell_type":"markdown","source":"# Data tokenization"},{"metadata":{"id":"OHL_4eiq_zQM","trusted":true},"cell_type":"code","source":"train = pd.read_json('../input/text-classification/github/embold_train.json')\ntrain_extra = pd.read_json('../input/text-classification/github/embold_train_extra.json')\ntrain = pd.concat([train, train_extra], ignore_index=True)\ntest = pd.read_json('../input/text-classification/github/embold_test.json')\n# 0: bug, 1: feature, 2: question","execution_count":null,"outputs":[]},{"metadata":{"id":"CqZYIT5Y_zQM","outputId":"fa89ff0f-59a8-4569-b7dd-eed60a92ba24","trusted":true},"cell_type":"code","source":"train['text'] = train.title + ' ' + train.body\ntest['text'] = test.title + ' ' + test.body\n\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(train), len(test))","execution_count":null,"outputs":[]},{"metadata":{"id":"UinllUwh_zQM","trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\ntrain, val = train_test_split(train, test_size=.2)","execution_count":null,"outputs":[]},{"metadata":{"id":"kGcxBT5D_zRw","trusted":true},"cell_type":"code","source":"train_texts = train[:20_000].text.to_list()#to_numpy()\nval_texts = val[:15_000].text.to_list()#to_numpy()\ntest_texts = val[-15_000:].text.to_list()\n#test_texts = test[:2000].text.to_list()#to_numpy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_labels = train[:20_000].label.to_list()#to_numpy()\nval_labels = val[:15_000].label.to_list()#to_numpy()\ntest_labels = val[-15_000:].label.to_list()\n#test_labels = test[:2000].label.to_list()#to_numpy()","execution_count":null,"outputs":[]},{"metadata":{"id":"Qyd4nwIe_zRw","outputId":"eaf2959d-2153-42f7-fc6b-1e5eba00fcd4","trusted":true},"cell_type":"code","source":"from transformers import DistilBertTokenizerFast\ntokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')","execution_count":null,"outputs":[]},{"metadata":{"id":"6UK7LCDx_zRw","trusted":true},"cell_type":"code","source":"train_encodings = tokenizer(train_texts, truncation=True, padding=True)\nval_encodings = tokenizer(val_texts, truncation=True, padding=True)\ntest_encodings = tokenizer(test_texts, truncation=True, padding=True)","execution_count":null,"outputs":[]},{"metadata":{"id":"TzR2nEm__zRw"},"cell_type":"markdown","source":"# Datasets"},{"metadata":{"id":"_4VlKKD1_zRw","trusted":true},"cell_type":"code","source":"import torch\n\nclass GitDataset(torch.utils.data.Dataset):\n    def __init__(self, encodings, labels):\n        self.encodings = encodings\n        self.labels = labels\n\n    def __getitem__(self, idx):\n        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n        item['labels'] = torch.tensor(self.labels[idx])\n        return item\n\n    def __len__(self):\n        return len(self.labels)\n\ntrain_dataset = GitDataset(train_encodings, train_labels)\nval_dataset = GitDataset(val_encodings, val_labels)\ntest_dataset = GitDataset(test_encodings, test_labels)","execution_count":null,"outputs":[]},{"metadata":{"id":"MqUdRCq0_zRw"},"cell_type":"markdown","source":"# Fine-tuning"},{"metadata":{"id":"Zij6KuFvQSuM","trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n\ndef compute_metrics(pred):\n    labels = pred.label_ids\n    preds = pred.predictions.argmax(-1)\n    #precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')\n    acc = accuracy_score(labels, preds)\n    return {\n        'accuracy': acc,\n        #'f1': f1,\n        #'precision': precision,\n        #'recall': recall\n    }\n","execution_count":null,"outputs":[]},{"metadata":{"id":"ayOS1NvwXQT3","trusted":true},"cell_type":"code","source":"#model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\")\nmodel = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=3)","execution_count":null,"outputs":[]},{"metadata":{"id":"lPNQBTHQ_zRw","trusted":true},"cell_type":"code","source":"training_args = TrainingArguments(\n    output_dir='./results',          # output directory\n    num_train_epochs=3,              # total # of training epochs\n    per_device_train_batch_size=16,  # batch size per device during training\n    per_device_eval_batch_size=64,   # batch size for evaluation\n    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n    weight_decay=0.01,               # strength of weight decay\n    logging_dir='./logs',            # directory for storing logs\n    logging_steps=10,\n)\n\ntrainer = Trainer(\n    model=model,                         # the instantiated ðŸ¤— Transformers model to be trained\n    args=training_args,                  # training arguments, defined above\n    train_dataset=train_dataset,         # training dataset\n    eval_dataset=test_dataset,           # evaluation dataset\n    compute_metrics = compute_metrics\n)","execution_count":null,"outputs":[]},{"metadata":{"id":"oXuEBGb9KdL8","trusted":true},"cell_type":"code","source":"model.to('cuda')","execution_count":null,"outputs":[]},{"metadata":{"id":"V2yJGp69_zRw","outputId":"1cdd8451-0a4b-49d4-af77-2a8d1ced09fb","trusted":true},"cell_type":"code","source":"trainer.train()","execution_count":null,"outputs":[]},{"metadata":{"id":"rxDQCuZzPqok","outputId":"75b80e65-f127-4077-dc5b-5d16d25d2712","trusted":true},"cell_type":"code","source":"trainer.evaluate()","execution_count":null,"outputs":[]},{"metadata":{"id":"X_WolaZ6OiWA","trusted":true},"cell_type":"code","source":"trainer.save_model('bert_github_kaggle')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"End\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}