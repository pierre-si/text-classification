{"cells":[{"metadata":{"id":"VtfD5gY8_zQM","trusted":true},"cell_type":"code","source":["import pickle\n","\n","import numpy as np\n","import pandas as pd\n","import torch\n","from transformers import BertForSequenceClassification, Trainer, TrainingArguments"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["device = 'cuda' if torch.cuda.is_available() else 'cpu'"],"execution_count":null,"outputs":[]},{"metadata":{"id":"L0kV2j_D_zQM"},"cell_type":"markdown","source":["# Data tokenization"]},{"metadata":{"trusted":true},"cell_type":"code","source":["with open(\"../input/text-classification-tfidf/github/X_train.pickle\", 'rb') as f:\n","    X_train = pickle.load(f)\n","with open(\"../input/text-classification-tfidf/github/\"+\"/X_test.pickle\", 'rb') as f:\n","    X_test = pickle.load(f)\n","with open(\"../input/text-classification-tfidf/github/\"+\"/y_train.pickle\", 'rb') as f:\n","    y_train = pickle.load(f)\n","with open(\"../input/text-classification-tfidf/github/\"+\"/y_test.pickle\", 'rb') as f:\n","    y_test = pickle.load(f)"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["train_texts = X_train.to_list()\n","train_labels = torch.tensor(y_train.to_list()).to(device)\n","test_texts = X_test.to_list()\n","test_labels = torch.tensor(y_test.to_list()).to(device)"],"execution_count":null,"outputs":[]},{"metadata":{"id":"Qyd4nwIe_zRw","outputId":"eaf2959d-2153-42f7-fc6b-1e5eba00fcd4","trusted":true},"cell_type":"code","source":["from transformers import DistilBertTokenizerFast\n","tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')"],"execution_count":null,"outputs":[]},{"metadata":{"id":"6UK7LCDx_zRw","trusted":true},"cell_type":"code","source":["# If the ``encoded_inputs`` passed are dictionary of numpy arrays, PyTorch tensors or TensorFlow tensors, the\n","# result will use the same type unless you provide a different tensor type with ``return_tensors``. In the\n","# case of PyTorch tensors, you will lose the specific device of your tensors however.\n","# â†’ les texts n'Ã©tant pas des tensors, tokenizer ne renvoyait pas de tensors, et donc le to(device) ne fonctionnait pas\n","train_encodings = tokenizer(train_texts, truncation=True, padding=True, return_tensors=\"pt\").to(device)\n","#val_encodings = tokenizer(val_texts, truncation=True, padding=True, return_tensors=\"pt\").to(device)\n","test_encodings = tokenizer(test_texts, truncation=True, padding=True, return_tensors=\"pt\").to(device)"],"execution_count":null,"outputs":[]},{"metadata":{"id":"TzR2nEm__zRw"},"cell_type":"markdown","source":["# Datasets"]},{"metadata":{"trusted":true},"cell_type":"code","source":["# element_size in bytes\n","train_encodings.input_ids.element_size()*train_encodings.input_ids.nelement() /10**6"],"execution_count":null,"outputs":[]},{"metadata":{"id":"_4VlKKD1_zRw","trusted":true},"cell_type":"code","source":["import torch\n","\n","class GitDataset(torch.utils.data.Dataset):\n","    def __init__(self, encodings, labels):\n","        self.encodings = encodings\n","        self.labels = labels\n","\n","    def __getitem__(self, idx):\n","        item = {key: val[idx] for key, val in self.encodings.items()}\n","        item['labels'] = self.labels[idx]\n","        return item\n","\n","    def __len__(self):\n","        return len(self.labels)\n","\n","train_dataset = GitDataset(train_encodings, train_labels)\n","#val_dataset = GitDataset(val_encodings, val_labels)\n","test_dataset = GitDataset(test_encodings, test_labels)"],"execution_count":null,"outputs":[]},{"metadata":{"id":"MqUdRCq0_zRw"},"cell_type":"markdown","source":["# Fine-tuning"]},{"metadata":{"id":"Zij6KuFvQSuM","trusted":true},"cell_type":"code","source":["from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n","\n","def compute_metrics(pred):\n","    labels = pred.label_ids\n","    preds = pred.predictions.argmax(-1)\n","    #precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')\n","    acc = accuracy_score(labels, preds)\n","    return {\n","        'accuracy': acc,\n","        #'f1': f1,\n","        #'precision': precision,\n","        #'recall': recall\n","    }\n"],"execution_count":null,"outputs":[]},{"metadata":{"id":"ayOS1NvwXQT3","trusted":true},"cell_type":"code","source":["#model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\")\n","model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=3)"],"execution_count":null,"outputs":[]},{"metadata":{"id":"lPNQBTHQ_zRw","trusted":true},"cell_type":"code","source":["training_args = TrainingArguments(\n","    output_dir='../tmp/',          # output directory\n","    num_train_epochs=3,              # total # of training epochs\n","    per_device_train_batch_size=8,  # batch size per device during training\n","    per_device_eval_batch_size=32,   # batch size for evaluation\n","    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n","    weight_decay=0.01,               # strength of weight decay\n","    logging_dir='./logs',            # directory for storing logs\n","    logging_steps=10,\n",")\n","\n","trainer = Trainer(\n","    model=model,                         # the instantiated ðŸ¤— Transformers model to be trained\n","    args=training_args,                  # training arguments, defined above\n","    train_dataset=train_dataset,         # training dataset\n","    eval_dataset=test_dataset,           # evaluation dataset\n","    compute_metrics = compute_metrics\n",")"],"execution_count":null,"outputs":[]},{"metadata":{"id":"oXuEBGb9KdL8","trusted":true},"cell_type":"code","source":["model.to(device)"],"execution_count":null,"outputs":[]},{"metadata":{"id":"V2yJGp69_zRw","outputId":"1cdd8451-0a4b-49d4-af77-2a8d1ced09fb","trusted":true,"_kg_hide-output":false},"cell_type":"code","source":["trainer.train()"],"execution_count":null,"outputs":[]},{"metadata":{"id":"rxDQCuZzPqok","outputId":"75b80e65-f127-4077-dc5b-5d16d25d2712","trusted":true},"cell_type":"code","source":["trainer.evaluate()"],"execution_count":null,"outputs":[]},{"metadata":{"id":"X_WolaZ6OiWA","trusted":true},"cell_type":"code","source":["trainer.save_model('bert_github_kaggle')"],"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}